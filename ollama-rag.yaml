apiVersion: v1
kind: Pod
metadata:
  name: ollama-username
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: nvidia.com/gpu.product
            operator: In
            values:
            - NVIDIA-A10
  tolerations:
  - key: nautilus.io/mahi-tutorial
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
  volumes:
  - name: scratch
    emptyDir: {}
  - name: shm
    emptyDir:
      medium: Memory
      sizeLimit: 8Gi
  containers:
  - name: mypod
    image: ollama/ollama
    resources:
      limits:
        memory: 24Gi
        cpu: 4
        nvidia.com/gpu: 1
      requests:
        memory: 24Gi
        cpu: 4
        nvidia.com/gpu: 1
    command: ["/bin/bash", "-c"]
    args:
    - >-
        apt update;
        apt install -y pip wget vim;
        pip3 install -U langchain-cli;
        pip3 install -U langchain-community;
        pip3 install -U chromadb;
        pip3 install -U sentence-transformers==2.2.2;
        export HOME=/scratch; 
        cd $HOME;
        wget https://www.gutenberg.org/cache/epub/55084/pg55084.txt;
        sleep 3600;
    volumeMounts:
            - name: scratch
              mountPath: /scratch
            - name: shm
              mountPath: /dev/shm
